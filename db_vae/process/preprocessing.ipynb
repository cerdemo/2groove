{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import mido\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add a brief explanation of the preprocessing steps.\n",
    "\n",
    "References:\n",
    "<br/>\n",
    "Simon et al. (2018) \"Learning Latent Space...\" use:\n",
    "- 128 note on/offs\n",
    "- 8 velocity change events -> quantized into 8 bins\n",
    "- 96 time-shift (offset) events -> 24 step/quarter note.\n",
    "- LSTM VAE (bidire. LSTM encoder w 1024 nodes, and a forward LSTM decoder with 3 layers of 512 nodes each)\n",
    "- Conditioning\n",
    "- latent space dim 512\n",
    "- batch size 256\n",
    "- Adam opt., l_rate 1e3 to 1e-5 with exponential decay rate 0.9999\n",
    "- 100000 gradient steps\n",
    "- Sampling autoregressively with a temperature param that controls the uniformity of the distribution\n",
    "- 176K MIDI files (all 4/4) ->4092681 (1-bar) splits (deduped measures)\n",
    "- ...more in the paper. <br/>\n",
    "<br/>\n",
    "\n",
    "Gillick et al. (2019) \"Learning to Groove...\" use:\n",
    "- Groove MIDI dataset\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "\n",
    "def mido2pretty(midi_data):\n",
    "    '''Convert Mido data structure to pretty_midi\n",
    "    TODO: Check the loop. Somethings odd...'''\n",
    "    # Create a PrettyMIDI object\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "\n",
    "    # Create an instrument object to add notes to\n",
    "    instrument = pretty_midi.Instrument(program=0, is_drum=False)\n",
    "\n",
    "    # Keep track of the current time in ticks\n",
    "    current_time = 0\n",
    "\n",
    "    # Loop through each message in the mido track\n",
    "    for msg in midi_data.tracks[0]:\n",
    "        # Update the current time by the message time delta\n",
    "        current_time += msg.time\n",
    "        \n",
    "        # If the message is a note on message, add the note to the instrument\n",
    "        if msg.type == 'note_on':\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=msg.velocity,\n",
    "                pitch=msg.note,\n",
    "                start=current_time / midi_data.ticks_per_beat,\n",
    "                end=(current_time + msg.time) / midi_data.ticks_per_beat,\n",
    "            )\n",
    "            instrument.notes.append(note)\n",
    "\n",
    "    # Add the instrument to the PrettyMIDI object\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "\n",
    "\n",
    "def get_pitches(midi_data, inst=0, mido=True):\n",
    "    # Get the note pitches of a single instrument in a MIDI track\n",
    "    #TODO: add NOT mido\n",
    "    pitches = []\n",
    "    if mido:\n",
    "        pmidi_data = mido2pretty(midi_data)\n",
    "    # else:\n",
    "    #     pmidi_data = midi_data\n",
    "        for i, _ in enumerate(pmidi_data.instruments[inst].notes):\n",
    "            pitch = pmidi_data.instruments[inst].notes[i].pitch\n",
    "            pitches.append(pitch)\n",
    "        pitches = np.array(pitches)\n",
    "    return pitches\n",
    "\n",
    "\n",
    "def get_onsets(midifile):\n",
    "    '''This function returns the note onsets of a midi file using Mido.'''\n",
    "    note_onsets = []\n",
    "    current_time = 0\n",
    "    current_notes = {}\n",
    "    \n",
    "    for msg in mido.MidiFile(midifile):\n",
    "        current_time += msg.time\n",
    "        \n",
    "        if msg.type == 'note_on':\n",
    "            if msg.velocity > 0:\n",
    "                current_notes[msg.note] = current_time\n",
    "            else:\n",
    "                try:\n",
    "                    note_onset = current_notes.pop(msg.note)\n",
    "                    note_duration = current_time - note_onset\n",
    "                    note_onsets.append((note_onset, msg.note)) #you can add note_duration too\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    return note_onsets\n",
    "\n",
    "\n",
    "#Offset calculation - Looks the most reliable but REQUIREs more work!\n",
    "def get_offsets(midifile, subdivision=8):\n",
    "    '''This function returns the note onsets of a midi file using Mido, \n",
    "    and calculate the temporal distance with quantized onsets.'''\n",
    "    note_onsets = []\n",
    "    current_time = 0\n",
    "    current_notes = {}\n",
    "    mid = mido.MidiFile(midifile)\n",
    "\n",
    "    for msg in mid:\n",
    "        current_time += msg.time\n",
    "        \n",
    "        if msg.type == 'note_on':\n",
    "            if msg.velocity > 0:\n",
    "                current_notes[msg.note] = current_time\n",
    "            else:\n",
    "                try:\n",
    "                    note_onset = current_notes.pop(msg.note)\n",
    "                    note_duration = current_time - note_onset\n",
    "                    note_onsets.append(note_onset) \n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    #quant interval:\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    subdivision = subdivision\n",
    "    ticks_per_div = ticks_per_beat/subdivision\n",
    "\n",
    "\n",
    "    quantized_onsets = [round(onset / ticks_per_div) * ticks_per_div for onset in note_onsets]\n",
    "    temporal_distance = [(q - o) / ticks_per_div for o, q in zip(note_onsets, quantized_onsets)]\n",
    "    norm_list = [max(-0.5, min(0.5, d)) for d in temporal_distance]\n",
    "    offsets_df = pd.DataFrame(norm_list, columns=['offsets'])\n",
    "\n",
    "    return offsets_df\n",
    "\n",
    "\n",
    "def get_meta(midi_file):\n",
    "    '''This function returns the tempo of a midi file using Mido.'''\n",
    "    if isinstance(midi_file, str):\n",
    "        input_midi = mido.MidiFile(midi_file)\n",
    "    elif isinstance(midi_file, mido.MidiFile):\n",
    "        input_midi = midi_file\n",
    "         \n",
    "    meta_msgs = [msg for msg in input_midi if msg.is_meta]\n",
    "    metas={}\n",
    "    for msg in meta_msgs:\n",
    "        metas.update(msg.dict())\n",
    "    return metas\n",
    "\n",
    "\n",
    "def get_midi_type(input_file):\n",
    "    '''as the name suggests...'''\n",
    "    if isinstance(input_file, str):\n",
    "        input_midi = mido.MidiFile(input_file)\n",
    "    elif isinstance(input_file, mido.MidiFile):\n",
    "        input_midi = input_file\n",
    "    return input_midi.type\n",
    "\n",
    "\n",
    "def show_score(midi_file):\n",
    "    '''Returns the score of a midi file as sheet music'''\n",
    "    from music21 import converter, instrument, note, chord\n",
    "    score = converter.parse(midi_file).chordify()\n",
    "    return score.show()\n",
    "\n",
    "\n",
    "def np_onehot(indices, depth, dtype=bool):\n",
    "    \"\"\"Converts 1D array of indices to a one-hot 2D array with given depth.\"\"\"\n",
    "    onehot_seq = np.zeros((len(indices), depth), dtype=dtype)\n",
    "    onehot_seq[np.arange(len(indices)), indices] = 1.0\n",
    "    return onehot_seq\n",
    "\n",
    "def is_shorter_or_longer_than_n_bars(midi_file_path, n_bars=2, time_signature=(4, 4), shorter=True):\n",
    "    if isinstance(midi_file_path, str):\n",
    "        midi_file = mido.MidiFile(midi_file_path)\n",
    "    elif isinstance(midi_file_path, mido.MidiFile):\n",
    "        midi_file = midi_file_path\n",
    "\n",
    "    # Calculate the length of the MIDI file in seconds\n",
    "    midi_length_seconds = midi_file.length\n",
    "\n",
    "    # Calculate the length of n bars in seconds\n",
    "    ticks_per_beat = midi_file.ticks_per_beat\n",
    "    time_sig_numerator = time_signature[0]\n",
    "    time_sig_denominator = time_signature[1]\n",
    "\n",
    "    for msg in midi_file.tracks[0]:\n",
    "        if msg.type == \"time_signature\":\n",
    "            time_sig_numerator = msg.numerator\n",
    "            time_sig_denominator = msg.denominator\n",
    "            break\n",
    "\n",
    "    quarter_notes_per_bar = time_sig_numerator * (4 / time_sig_denominator)\n",
    "    ticks_per_bar = ticks_per_beat * quarter_notes_per_bar\n",
    "    n_bars_length_ticks = n_bars * ticks_per_bar\n",
    "\n",
    "    # Convert ticks to seconds\n",
    "    tempo = 500000  # Default tempo is 120 BPM\n",
    "    for msg in midi_file.tracks[0]:\n",
    "        if msg.type == \"set_tempo\":\n",
    "            tempo = msg.tempo\n",
    "            break\n",
    "\n",
    "    n_bars_length_seconds = mido.tick2second(n_bars_length_ticks, ticks_per_beat, tempo)\n",
    "\n",
    "    # Compare the length of the MIDI file with the length of n bars\n",
    "    if shorter:\n",
    "        return midi_length_seconds < n_bars_length_seconds\n",
    "    return midi_length_seconds > n_bars_length_seconds\n",
    "\n",
    "\n",
    "\n",
    "def print_zero_time_events(midi_path):\n",
    "    midi_file = mido.MidiFile(midi_path)\n",
    "    for i, track in enumerate(midi_file.tracks):\n",
    "        print(f\"Track {i}:\")\n",
    "        for msg in track:\n",
    "            if msg.time == 0:\n",
    "                print(msg)\n",
    "# # Example usage\n",
    "# midi_file_path = longs_w_issue[0]\n",
    "# print_zero_time_events(midi_file_path)\n",
    "\n",
    "\n",
    "def beat_threshold(df, bars=2):\n",
    "    #TODO define a function that ignores the dataframes shorter than the given amount of bars\n",
    "    pass \n",
    "\n",
    "def findstr(text, word_to_search):\n",
    "    # Compile the regular expression pattern using the re.IGNORECASE flag\n",
    "    pattern = re.compile(word_to_search, re.IGNORECASE)\n",
    "    return pattern.findall(text) \n",
    "\n",
    "def list2text(list, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in list:\n",
    "            f.write(str(item))\n",
    "            f.write('\\n')\n",
    "\n",
    "def extract_time_signature(midi_file_path):\n",
    "    midi_file = mido.MidiFile(midi_file_path)\n",
    "\n",
    "    for track in midi_file.tracks:\n",
    "        for msg in track:\n",
    "            if msg.type == 'time_signature':\n",
    "                return f\"{msg.numerator}/{msg.denominator}\"\n",
    "\n",
    "    # If no time signature is found, return a default value (e.g., '4/4').\n",
    "    return \"Other\"\n",
    "\n",
    "def print_uncommon_events(midi_path):\n",
    "    uncommon_event_types = [\"sysex\", \"polytouch\", \"aftertouch\"]\n",
    "\n",
    "    midi_file = mido.MidiFile(midi_path)\n",
    "    for i, track in enumerate(midi_file.tracks):\n",
    "        print(f\"Track {i}:\")\n",
    "        for msg in track:\n",
    "            if msg.type in uncommon_event_types:\n",
    "                print(msg)\n",
    "\n",
    "def add_delay_to_zero_time_notes(midi_path, output_path, delay=1):\n",
    "    input_midi = mido.MidiFile(midi_path)\n",
    "    output_midi = mido.MidiFile(type=input_midi.type)\n",
    "    \n",
    "    for track in input_midi.tracks:\n",
    "        new_track = mido.MidiTrack()\n",
    "        output_midi.tracks.append(new_track)\n",
    "\n",
    "        for msg in track:\n",
    "            if msg.type == 'note_on' and msg.time == 0:\n",
    "                msg.time = delay\n",
    "            new_track.append(msg)\n",
    "\n",
    "    output_midi.save(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More UTILITY functions for the preprocessing of MIDI files\n",
    "\n",
    "def extend_midi_bars(input_file, num_bars=4, time_signature=(4, 4)):\n",
    "\n",
    "    '''This function extends the drum loop to the desired number of bars without time-stretching. \n",
    "    It will turn a 1-bar loop into a 2-bar loop, a 2-bar loop into a 4-bar loop, and so on.'''\n",
    "\n",
    "    input_midi = mido.MidiFile(input_file)\n",
    "\n",
    "    # Calculate ticks per bar and total ticks for desired number of bars\n",
    "    ticks_per_beat = input_midi.ticks_per_beat\n",
    "    ticks_per_bar = ticks_per_beat * time_signature[0]\n",
    "    total_ticks = ticks_per_bar * num_bars\n",
    "\n",
    "    # Create a new MidiFile object for the output\n",
    "    output_midi = mido.MidiFile(ticks_per_beat=ticks_per_beat)\n",
    "\n",
    "    for track in input_midi.tracks:\n",
    "        output_track = mido.MidiTrack()\n",
    "        output_midi.tracks.append(output_track)\n",
    "\n",
    "        # Duplicate meta messages to the output track\n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                output_track.append(msg.copy())\n",
    "\n",
    "        # Calculate the original loop length in ticks\n",
    "        loop_length = 0\n",
    "        for msg in track:\n",
    "            if not msg.is_meta:\n",
    "                loop_length += msg.time\n",
    "\n",
    "        # Extend the loop to the desired number of bars\n",
    "        accumulated_ticks = 0\n",
    "        while accumulated_ticks < total_ticks:\n",
    "            current_ticks = 0\n",
    "            for msg in track:\n",
    "                if not msg.is_meta:\n",
    "                    # Calculate the tick position in the output track\n",
    "                    output_ticks = current_ticks + accumulated_ticks\n",
    "\n",
    "                    # If the message goes beyond the desired length, break the loop\n",
    "                    if output_ticks >= total_ticks:\n",
    "                        break\n",
    "\n",
    "                    # Clone the message and add it to the output track\n",
    "                    output_msg = msg.copy(time=msg.time)\n",
    "                    output_track.append(output_msg)\n",
    "                    current_ticks += msg.time\n",
    "\n",
    "            # Update the accumulated_ticks for the next loop iteration\n",
    "            accumulated_ticks += loop_length\n",
    "\n",
    "    return output_midi\n",
    "\n",
    "\n",
    "def truncate_midi_bars(input_file, num_bars=4, time_signature=(4, 4)):\n",
    "    '''This function removes any extra content that extends beyond the desired number of bars. \n",
    "    It takes an input MIDI file, processes it to match the desired number of bars.'''\n",
    "\n",
    "    if isinstance(input_file, str):\n",
    "        input_midi = mido.MidiFile(input_file)\n",
    "    elif isinstance(input_file, mido.MidiFile):\n",
    "        input_midi = input_file\n",
    "\n",
    "    # Calculate ticks per bar and total ticks for desired number of bars\n",
    "    ticks_per_beat = input_midi.ticks_per_beat\n",
    "    ticks_per_bar = ticks_per_beat * time_signature[0]\n",
    "    total_ticks = ticks_per_bar * num_bars\n",
    "\n",
    "    # Create a new MidiFile object for the output\n",
    "    output_midi = mido.MidiFile(ticks_per_beat=ticks_per_beat)\n",
    "\n",
    "    for track in input_midi.tracks:\n",
    "        output_track = mido.MidiTrack()\n",
    "        output_midi.tracks.append(output_track)\n",
    "        current_ticks = 0\n",
    "\n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                output_track.append(msg.copy())\n",
    "            else:\n",
    "                # Calculate the tick position in the output track\n",
    "                output_ticks = current_ticks + msg.time\n",
    "\n",
    "                # If the message goes beyond the desired length, break the loop\n",
    "                if output_ticks >= total_ticks:\n",
    "                    break\n",
    "\n",
    "                # Clone the message and add it to the output track\n",
    "                output_msg = msg.copy(time=msg.time)\n",
    "                output_track.append(output_msg)\n",
    "                current_ticks += msg.time\n",
    "\n",
    "    return output_midi\n",
    "\n",
    "def proc_meta(df, add_genre=False, tensor=False):\n",
    "    '''Process the metadata and output DataFrame or tensor'''\n",
    "    tempo = df.loc[df['type']=='set_tempo', 'tempo'].values[0]\n",
    "    data = {'type': ['time_signature', 'tempo'],\n",
    "            'value': [(df.numerator[0], df.denominator[0]), tempo]}\n",
    "    if add_genre:\n",
    "        #TODO: one-hot or integer encode the genre info later\n",
    "        pass\n",
    "    \n",
    "    if tensor:\n",
    "        return tf.constant([df.numerator[0], df.denominator[0], tempo], dtype=tf.float32)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File management\n",
    "\n",
    "class MIDIfiles:\n",
    "\n",
    "    def __init__(self, midi_dir):\n",
    "        '''This class imports a list of midi files in a given path.'''\n",
    "        self.midi_dir = midi_dir\n",
    "    \n",
    "    def get_paths(self):\n",
    "        '''This function returns a list of midi files in a given path.'''\n",
    "        midi_files=[]\n",
    "        for path, subdirs, files in os.walk(self.midi_dir): \n",
    "            for file in files:\n",
    "                if file.endswith('.mid'):\n",
    "                    midfile = os.path.join(path, file)\n",
    "                    midi_files.append(midfile)\n",
    "        return midi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIgroup:\n",
    "\n",
    "    def __init__(self, midi_path, n_bars=2):\n",
    "        self.midi_path = midi_path\n",
    "        self.n_bars = n_bars\n",
    "\n",
    "    def is_44(self):\n",
    "        '''This function returns True if the midi file is in 4/4 time signature.'''\n",
    "        if extract_time_signature(self.midi_path) == '4/4':\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_short(self):\n",
    "        '''This function returns True if the midi file is shorter than 2 bars.'''\n",
    "        if is_shorter_or_longer_than_n_bars(self.midi_path, self.n_bars):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_long(self):\n",
    "        '''This function returns True if the midi file is longer than 2 bars.'''\n",
    "        if is_shorter_or_longer_than_n_bars(self.midi_path, self.n_bars, shorter=False):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_fill(self):\n",
    "        '''This function returns True if the midi file is a fill.'''\n",
    "        if findstr(self.midi_path, 'fill'):\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIRECTORY\n",
    "dat_dir = \"/Users/cagrierdem/Desktop/ongoing/POSTDOC/dB_workspace/drumbot/dB_dat\"\n",
    "MAIN_DIR = os.path.join(dat_dir, \"DOOM\")\n",
    "TEST_DIR = os.path.join(dat_dir, \"TEST\")\n",
    "midi_files = MIDIfiles(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, there are 2953 MIDI files in the dataset.\n",
      " 406 are 4/4 loops that are longer than 2 bars.\n",
      " 98 are 4/4 fills, of which 39 are short and 59 are long.\n",
      " We disregard a total of 2449 files, which are not 4/4.\n",
      "\n",
      " Among 4/4 loops, 176 are Type0 and 230 are Type1 MIDI\n"
     ]
    }
   ],
   "source": [
    "#Grouping MIDI files in the dataset \n",
    "#based on their time signature and whether they are loops or fills\n",
    "\n",
    "fills44 = []\n",
    "shortfills44 = []\n",
    "longfills44 = []\n",
    "loops44 = []\n",
    "rest=[]\n",
    "num_bars = 2\n",
    "for file in midi_files.get_paths():\n",
    "    check = MIDIgroup(file, n_bars=num_bars)\n",
    "    #1) Is the file is 4/4 (has metadata as 4/4)?\n",
    "    if check.is_44():\n",
    "        #2) Is the file a fill (is it in the name)?\n",
    "        if check.is_fill():\n",
    "            fills44.append(file)\n",
    "            #3) Is the fill shorter or longer than 4 bars?\n",
    "            if check.is_short():\n",
    "                shortfills44.append(file)\n",
    "            else:\n",
    "                longfills44.append(file)\n",
    "        else:\n",
    "            #All the 4/4 files that are not fills\n",
    "            loops44.append(file)\n",
    "    else:\n",
    "        #All the files that are not 4/4\n",
    "        rest.append(file)\n",
    "\n",
    "#Finally:\n",
    "print(\n",
    "    'Currently, there are {} MIDI files in the dataset.\\n'.format(len(midi_files.get_paths())),\n",
    "    '{} are 4/4 loops that are longer than {} bars.\\n'.format(len(loops44), num_bars),\n",
    "    '{} are 4/4 fills, of which {} are short and {} are long.\\n'.format(len(fills44), len(shortfills44), len(longfills44)),\n",
    "    'We disregard a total of {} files, which are not 4/4.\\n'.format(len(rest))\n",
    ")\n",
    "\n",
    "type0 = []\n",
    "type1 = []\n",
    "for loop in loops44:\n",
    "    type0.append(loop) if get_midi_type(loop) == 0 else type1.append(loop)\n",
    "print(f' Among 4/4 loops, {len(type0)} are Type0 and {len(type1)} are Type1 MIDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 different resolutions in the dataset:\n",
      "\n",
      "96-tick occurs 137 times.\n",
      "960-tick occurs 39 times.\n",
      "15360-tick occurs 230 times.\n"
     ]
    }
   ],
   "source": [
    "#TODO: EXPLORE HOW TO DEAL WITH DIFFERENT RESOLUTIONS\n",
    "\n",
    "resolutions=[]\n",
    "res=[]\n",
    "for i, midi_file in enumerate(loops44):\n",
    "    midi_data = mido.MidiFile(midi_file)\n",
    "    ticks = midi_data.ticks_per_beat\n",
    "    resolutions.append([i, ticks])\n",
    "    res.append(ticks)\n",
    "\n",
    "resarr = np.array(res)\n",
    "occured_ticks = np.unique(resarr)\n",
    "print(\"There are {} different resolutions in the dataset:\\n\".format(len(occured_ticks)))\n",
    "for t in occured_ticks:\n",
    "    print(\"{}-tick occurs {} times.\".format(t, res.count(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = input(\"Wanna export as text?\")\n",
    "# if q.startswith('y') or q.startswith('Y'):\n",
    "#     with open ('dataset_midi_res.txt', 'w') as f:\n",
    "#         for item in resolutions:\n",
    "#             f.write(str(item))\n",
    "#             f.write('\\n')\n",
    "# else:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticks per beat value is consistent across all MIDI files: 960\n"
     ]
    }
   ],
   "source": [
    "# Check if the ticks per beat value is the same across all MIDI files\n",
    "non_consts = []\n",
    "midi_ticks = []\n",
    "ticks_per_beat = None\n",
    "for midi_file in loops44:\n",
    "    midi_data = mido.MidiFile(midi_file)\n",
    "    if ticks_per_beat is None:\n",
    "        ticks_per_beat = midi_data.ticks_per_beat\n",
    "    elif midi_data.ticks_per_beat != ticks_per_beat:\n",
    "        # print(f'Error: ticks per beat value is not consistent across MIDI files')\n",
    "        non_consts.append([midi_file, midi_data.ticks_per_beat])\n",
    "\n",
    "if ticks_per_beat is not None:\n",
    "    print(f'Ticks per beat value is consistent across all MIDI files: {ticks_per_beat}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and list the MIDI files that don't have tempo information\n",
    "wout_meta = []\n",
    "for i, midi_path in enumerate(loops44):\n",
    "    metadata = get_meta(midi_path)\n",
    "    if 'tempo' not in metadata:\n",
    "        wout_meta.append(midi_path)\n",
    "\n",
    "# list2text(wout_meta, 'midi_wout_tempo')\n",
    "\n",
    "# There are 1744 files, each has metadata but NO tempo information. \n",
    "#And these are all from 8000000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIDI PREPROCESSING UTILS\n",
    "\n",
    "def update_tempo_from_path(midi_path, save_to_file=False, verbose=False):\n",
    "    '''Add tempo information to a MIDI file if it's not present.\n",
    "    The function looks for a number followed by \"BPM\" (case-insensitive) in the file path, \n",
    "    extracts the BPM, checks for the presence of \"_to<number>\" at the end of the filename \n",
    "    and updates the tempo information accordingly, even if the MIDI file already has tempo information.'''\n",
    "    \n",
    "    midi_file = mido.MidiFile(midi_path)\n",
    "\n",
    "    # Extract BPM from the file path using a regex pattern\n",
    "    bpm_pattern = re.compile(r'\\d{2,3}(?=BPM)', re.IGNORECASE)\n",
    "    match = bpm_pattern.search(midi_path)\n",
    "\n",
    "    # Extract the custom BPM from the file path, if present\n",
    "    custom_bpm_pattern = re.compile(r'_to(\\d{2,3})', re.IGNORECASE)\n",
    "    custom_match = custom_bpm_pattern.search(midi_path)\n",
    "    custom_bpm = None\n",
    "\n",
    "    if custom_match:\n",
    "        custom_bpm = int(custom_match.group(1))\n",
    "\n",
    "    # Check if the MIDI file has tempo information\n",
    "    has_tempo = False\n",
    "    for track in midi_file.tracks:\n",
    "        for msg in track:\n",
    "            if msg.is_meta and msg.type == 'set_tempo':\n",
    "                has_tempo = True\n",
    "                break\n",
    "        if has_tempo:\n",
    "            break\n",
    "\n",
    "    if match or custom_bpm or not has_tempo:\n",
    "        # Add or update tempo information\n",
    "        if not has_tempo:\n",
    "            bpm = int(match.group()) if match else 120\n",
    "            tempo = mido.bpm2tempo(bpm)\n",
    "            new_track = [mido.MetaMessage('set_tempo', tempo=tempo, time=0)]\n",
    "            new_track.extend(midi_file.tracks[0])\n",
    "            midi_file.tracks[0] = new_track\n",
    "            if verbose:\n",
    "                print(f\"Tempo information added to: {midi_path}\")\n",
    "\n",
    "        if custom_bpm:\n",
    "            tempo = mido.bpm2tempo(custom_bpm)\n",
    "            for track in midi_file.tracks:\n",
    "                for msg in track:\n",
    "                    if msg.is_meta and msg.type == 'set_tempo':\n",
    "                        msg.tempo = tempo\n",
    "            if verbose:\n",
    "                print(f\"Tempo information updated to {custom_bpm} in: {midi_path}\")\n",
    "\n",
    "        if save_to_file:\n",
    "            midi_file.save(midi_path)\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"No BPM information found in the path: {midi_path}\")\n",
    "\n",
    "    return midi_file\n",
    "\n",
    "\n",
    "def merge_tracks(input_midi):\n",
    "    '''This function takes a multi-track MIDI file \n",
    "    and merges its tracks into a single track while preserving the timing & metadata'''\n",
    "    if isinstance(input_midi, str):\n",
    "        input_midi = mido.MidiFile(input_midi)\n",
    "\n",
    "    merged_midi = mido.MidiFile(type=0, ticks_per_beat=input_midi.ticks_per_beat)\n",
    "    merged_track = mido.MidiTrack()\n",
    "    merged_midi.tracks.append(merged_track)\n",
    "\n",
    "    # To keep track of whether the meta messages have been added to the merged track\n",
    "    time_signature_added = False\n",
    "    set_tempo_added = False\n",
    "\n",
    "    for track in input_midi.tracks:\n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                if msg.type == 'time_signature' and not time_signature_added:\n",
    "                    merged_track.append(msg.copy())\n",
    "                    time_signature_added = True\n",
    "                elif msg.type == 'set_tempo' and not set_tempo_added:\n",
    "                    merged_track.append(msg.copy())\n",
    "                    set_tempo_added = True\n",
    "                elif msg.type not in ('time_signature', 'set_tempo'):\n",
    "                    merged_track.append(msg.copy())\n",
    "            else:\n",
    "                merged_track.append(msg.copy())\n",
    "\n",
    "    return merged_midi\n",
    "\n",
    "\n",
    "def keep_initial_metadata(midi_file):\n",
    "    '''This function reads the input MIDI file and creates a new MIDI file with the same type. \n",
    "    It then goes through each track and message, copying the messages to the new MIDI file. \n",
    "    The function keeps only the initial tempo and time signature events, skipping any subsequent changes. \n",
    "    All other meta messages and non-meta messages are preserved.'''\n",
    "    if isinstance(midi_file, str):\n",
    "        input_midi = mido.MidiFile(midi_file)\n",
    "    elif isinstance(midi_file, mido.MidiFile):\n",
    "        input_midi = midi_file\n",
    "\n",
    "    output_midi = mido.MidiFile(type=input_midi.type)\n",
    "    \n",
    "    for track in input_midi.tracks:\n",
    "        new_track = mido.MidiTrack()\n",
    "        output_midi.tracks.append(new_track)\n",
    "\n",
    "        # Keep track of whether the initial tempo and time signature have been found\n",
    "        initial_tempo_found = False\n",
    "        initial_time_signature_found = False\n",
    "\n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                if msg.type == 'set_tempo' and not initial_tempo_found:\n",
    "                    new_track.append(msg)\n",
    "                    initial_tempo_found = True\n",
    "                elif msg.type == 'time_signature' and not initial_time_signature_found:\n",
    "                    new_track.append(msg)\n",
    "                    initial_time_signature_found = True\n",
    "                elif msg.type not in ('set_tempo', 'time_signature'):\n",
    "                    new_track.append(msg)\n",
    "            else:\n",
    "                new_track.append(msg)\n",
    "\n",
    "    return output_midi\n",
    "\n",
    "\n",
    "def unify_midi_res(midi_path, target_resolution=480, save_midi=False):\n",
    "    '''\n",
    "    Returns the MIDI file with a given resolution using Mido.\n",
    "    '''\n",
    "    if isinstance(midi_path, str):\n",
    "        midi_data = mido.MidiFile(midi_path)\n",
    "    elif isinstance(midi_path, mido.MidiFile):\n",
    "        midi_data = midi_path\n",
    "\n",
    "    # Calculate the conversion factor\n",
    "    source_resolution = midi_data.ticks_per_beat\n",
    "    conversion_factor = target_resolution / source_resolution\n",
    "\n",
    "    # Check if source resolution is different from the target resolution\n",
    "    if source_resolution != target_resolution:\n",
    "        for track in midi_data.tracks:\n",
    "            for event in track:\n",
    "                if event.type in ['note_on', 'note_off', 'control_change']:\n",
    "                    # Scale the tick values of note on/off and control change events\n",
    "                    event.time = round(event.time * conversion_factor)\n",
    "                # Tempo events are not modified, as the relationship between ticks and real-world time is maintained automatically\n",
    "\n",
    "        # Update the ticks_per_beat of the MIDI file to the target resolution\n",
    "        midi_data.ticks_per_beat = target_resolution\n",
    "        if save_midi:\n",
    "            # Save the modified MIDI file\n",
    "            output_path = os.path.splitext(midi_path)[0] + '_standardized.mid'\n",
    "            midi_data.save(output_path)\n",
    "\n",
    "    return midi_data\n",
    "\n",
    "\n",
    "def extract_note_info(midi_file):\n",
    "    '''This function extracts note information from the original and merged MIDI files \n",
    "    and then compare the results to ensure that the note information is preserved during the merging process'''\n",
    "    note_info = []\n",
    "    \n",
    "    for track in midi_file.tracks:\n",
    "        current_time = 0\n",
    "        for msg in track:\n",
    "            current_time += msg.time\n",
    "            if not msg.is_meta and msg.type == 'note_on':\n",
    "                note_info.append((msg.channel, msg.note, msg.velocity, current_time))\n",
    "    \n",
    "    return note_info\n",
    "\n",
    "\n",
    "def compare_midi_files(original_midi, converted_midi, tolerance=0.01):\n",
    "    '''This function compares MIDI file durations. \n",
    "    --> it compares the number of tracks and messages instead of instruments and notes\n",
    "    This is basically for a safety measure, in case TPQN conversion causes issues \n",
    "    (e.g., time-stretches) in the MIDI file structure'''\n",
    "\n",
    "    # Calculate the total duration of both files\n",
    "    original_duration = original_midi.length\n",
    "    converted_duration = converted_midi.length\n",
    "\n",
    "    # Compare the duration of the files\n",
    "    duration_difference = abs(original_duration - converted_duration)\n",
    "\n",
    "    # Initialize a dictionary to store the differences\n",
    "    differences = {}\n",
    "\n",
    "    # Check if the duration difference is above the tolerance\n",
    "    if duration_difference > tolerance:\n",
    "        differences['duration'] = (original_duration, converted_duration)\n",
    "\n",
    "    # Compare the number of tracks\n",
    "    if len(original_midi.tracks) != len(converted_midi.tracks):\n",
    "        differences['track_count'] = (len(original_midi.tracks), len(converted_midi.tracks))\n",
    "\n",
    "    # Compare the number of messages for each track\n",
    "    for i, (original_track, converted_track) in enumerate(zip(original_midi.tracks, converted_midi.tracks)):\n",
    "        if len(original_track) != len(converted_track):\n",
    "            differences[f'track_{i}_message_count'] = (len(original_track), len(converted_track))\n",
    "\n",
    "    return differences\n",
    "\n",
    "def midi_length_ticks(midi_object):\n",
    "    '''This function returns the maximum track length in ticks\n",
    "    by iterating through all the tracks in a MIDI file and\n",
    "    summing the ticks of all the messages'''\n",
    "\n",
    "    midi_length_ticks = 0\n",
    "    for track in midi_object.tracks:\n",
    "        track_length_ticks = sum(msg.time for msg in track)\n",
    "        midi_length_ticks = max(midi_length_ticks, track_length_ticks)\n",
    "\n",
    "    return midi_length_ticks\n",
    "\n",
    "\n",
    "def extract_metadata(midi_object):\n",
    "    '''as the name suggests... same as get_data() so TODO: combine them into one'''\n",
    "    metadata = []\n",
    "\n",
    "    for track in midi_object.tracks:\n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                metadata.append(msg.copy())\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def print_midi_metadata(midi_path):\n",
    "    '''not necessary, just for laziness...'''\n",
    "    midi_file = mido.MidiFile(midi_path)\n",
    "    for i, track in enumerate(midi_file.tracks):\n",
    "        print(f\"Track {i}:\")\n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                print(msg)\n",
    "\n",
    "\n",
    "def split_midi(input_file, num_bars_per_section=2, time_signature=(4, 4), verbose=False):\n",
    "    '''This function splits a MIDI file into sections of the desired length.'''\n",
    "\n",
    "    if isinstance(input_file, str):\n",
    "        input_midi = mido.MidiFile(input_file)\n",
    "    elif isinstance(input_file, mido.MidiFile):\n",
    "        input_midi = input_file\n",
    "    \n",
    "    #this verbose is new\n",
    "    if verbose:\n",
    "        print(\"Note messages before slicing:\")\n",
    "        for track in input_midi.tracks:\n",
    "            for msg in track:\n",
    "                if not msg.is_meta and msg.type in ('note_on', 'note_off'):\n",
    "                    print(msg)\n",
    "\n",
    "    ticks_per_beat = input_midi.ticks_per_beat #extract TPQN from the input file\n",
    "    ticks_per_bar = ticks_per_beat * time_signature[0] #calculate ticks per bar\n",
    "    ticks_per_section = ticks_per_bar * num_bars_per_section \n",
    "\n",
    "    #TODO: Make sure to cover the entire length of the input MIDI file!\n",
    "    # --> Calculate the total number of bars and round it up to the nearest integer before calculating the section start ticks.\n",
    "    # total_bars = math.ceil(input_midi.length * ticks_per_beat / ticks_per_bar)\n",
    "    total_bars = math.ceil(midi_length_ticks(input_midi) / ticks_per_bar)\n",
    "\n",
    "    metadata = extract_metadata(input_midi) #extract metadata from the input file\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Total length of the MIDI file: {} seconds & {} bars\".format(round(input_midi.length, 2), total_bars))\n",
    "        print(\"Ticks per beat: {}\".format(ticks_per_beat))\n",
    "        print(\"The loop will start from 0, will go to {} with steps of {}\".format(int(input_midi.length * ticks_per_beat), ticks_per_section))\n",
    "        s = 0\n",
    "\n",
    "    sections = []\n",
    "    # for section_start_tick in range(0, int(input_midi.length * ticks_per_beat), ticks_per_section):\n",
    "    for section_start_tick in range(0, total_bars * ticks_per_bar, ticks_per_section):\n",
    "        section_midi = mido.MidiFile(ticks_per_beat=ticks_per_beat)\n",
    "\n",
    "        if verbose:\n",
    "            s += 1\n",
    "            print(f'Section {s}')\n",
    "\n",
    "        for track in input_midi.tracks:\n",
    "            section_track = mido.MidiTrack()\n",
    "            section_track.extend(metadata) #adding the extracted metadata to each section\n",
    "            section_midi.tracks.append(section_track)\n",
    "\n",
    "            current_ticks = 0\n",
    "            section_ticks = 0\n",
    "            for msg in track:\n",
    "                current_ticks += msg.time\n",
    "                if section_start_tick <= current_ticks < section_start_tick + ticks_per_section:\n",
    "                    if msg.is_meta:\n",
    "                        if msg.type == \"end_of_track\":\n",
    "                            section_track.append(msg.copy(time=0))\n",
    "                        else:\n",
    "                            section_track.append(msg.copy())\n",
    "                    else:\n",
    "                        section_msg = msg.copy(time=current_ticks - section_ticks - section_start_tick)\n",
    "                        section_track.append(section_msg)\n",
    "                        section_ticks = current_ticks - section_start_tick  # Update the section_ticks\n",
    "\n",
    "        sections.append(section_midi)\n",
    "\n",
    "    #this verbose is new\n",
    "    if verbose: \n",
    "        for i, section in enumerate(sections):\n",
    "            print(f\"Note messages in section {i + 1}:\")\n",
    "            for track in section.tracks:\n",
    "                for msg in track:\n",
    "                    if not msg.is_meta and msg.type in ('note_on', 'note_off'):\n",
    "                        print(msg)\n",
    "\n",
    "\n",
    "    return sections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 TPQN -> 480 TPQN\n"
     ]
    }
   ],
   "source": [
    "TESTMID = loops44[49]\n",
    "test_midi = mido.MidiFile(TESTMID)  \n",
    "new_test_midi = unify_midi_res(TESTMID, target_resolution=480)\n",
    "print(\"{} TPQN -> {} TPQN\".format(test_midi.ticks_per_beat, new_test_midi.ticks_per_beat))\n",
    "\n",
    "#7440 idx'li track 15360 TPQN bi sacmaliyo baska bisi deneyelim\n",
    "#0 idx (240 TPQN) fistik gibi calisti\n",
    "#7399 idx 96 TPQN de fistik\n",
    "#5427 idx 6900 TPQN de gauyet oluyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 406 4/4 loops in the dataset, 328 are 2 bars or longer, 78 are shorter.\n",
      "There are a total of 98 lists of 2-bar splits now.\n",
      "0 files are suspicious.\n",
      "\n",
      "In total, There are 218 sliced loops in the dataset, and there are\n",
      "[1 2 3 4 5] splits per loop.\n"
     ]
    }
   ],
   "source": [
    "#Compare (inspect) MIDI files of adjusted resolutions to their original versions \n",
    "#and save them in a single folder in the given directory\n",
    "# output_directory = '/Users/cagrierdem/Desktop/ongoing/POSTDOC/practice/practiceMIDI/datatest'\n",
    "\n",
    "suspicious_files = []\n",
    "diffs=[]\n",
    "\n",
    "normal_loops=[]\n",
    "short_loops=[]\n",
    "\n",
    "splitted_loops = []\n",
    "splitted_loop_path=[]\n",
    "# Process each MIDI file in the input directory\n",
    "for i, midi_file in enumerate(loops44):\n",
    "\n",
    "    original_midi = mido.MidiFile(midi_file)\n",
    "\n",
    "    #Update the tempo information in metadata\n",
    "    updated_midi = update_tempo_from_path(midi_file, save_to_file=False, verbose=False)\n",
    "\n",
    "    #Convert all your MIDI files into single-track MIDI files\n",
    "    merged_updated_midi = merge_tracks(updated_midi)\n",
    "\n",
    "    # Convert the MIDI file\n",
    "    converted_midi = unify_midi_res(merged_updated_midi, target_resolution=480)\n",
    "\n",
    "    # Compare the original and converted MIDI files\n",
    "    differences = compare_midi_files(merged_updated_midi, converted_midi)\n",
    "    diffs.append(differences)\n",
    "\n",
    "    #According to the result of comparison:\n",
    "    if not differences:\n",
    "\n",
    "        #Disregard the files that are shorter than 2 bars\n",
    "        if is_shorter_or_longer_than_n_bars(converted_midi, n_bars=1, shorter=False):\n",
    "\n",
    "            #Keep the initial metadata –prevent duplicates\n",
    "            processed_midi = keep_initial_metadata(converted_midi)\n",
    "            normal_loops.append(processed_midi)\n",
    "\n",
    "            #Split the MIDI file into 2-bar sections\n",
    "            splits = split_midi(processed_midi, num_bars_per_section=2, verbose=False)\n",
    "\n",
    "            #Disregard split lists that have more than 8 splits\n",
    "            #TODO: Understand the problems when not disregarding\n",
    "            if len(splits) <= 8:\n",
    "                splitted_loops.append(splits) \n",
    "                splitted_loop_path.append(loop)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            short_loops.append(midi_file)\n",
    "\n",
    "    else:\n",
    "        # print(f\"Suspicious files: {original_midi} vs {converted_midi}\")\n",
    "        suspicious_files.append(midi_file)\n",
    "        print(\"Differences:\")\n",
    "        for key, value in differences.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"Out of {len(loops44)} 4/4 loops in the dataset, {len(normal_loops)} are 2 bars or longer, {len(short_loops)} are shorter.\")\n",
    "print(f\"There are a total of {len(splitted_loops)} lists of 2-bar splits now.\")\n",
    "print(f\"{len(suspicious_files)} files are suspicious.\\n\")\n",
    "\n",
    "#Check the lengths of the splitted loops\n",
    "splits = [len(loop_list) for loop_list in splitted_loops]\n",
    "total_loops = sum(splits)\n",
    "print(f'In total, There are {total_loops} sliced loops in the dataset, and there are\\n{np.unique(np.array(splits))} splits per loop.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the loops with anormal number of splits\n",
    "#Now that we disregard len(list) > 8, this loop may seem redundant, but can be functional in other cases, so keep it.\n",
    "anorms=[]\n",
    "for i, loop in enumerate(splitted_loops):\n",
    "    if len(loop) > 8:\n",
    "        anorms.append([i, len(loop)])\n",
    "\n",
    "print(len(anorms))\n",
    "#In the end, we should discard loops with more than 12 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 76 2-bar (splitted) loops in the new dataset.\n"
     ]
    }
   ],
   "source": [
    "#Iterate over each split in the new directory,\n",
    "#DISREGARD all splits that are longer than 2 bars\n",
    "#Save them into a new folder\n",
    "#TODO: It may be highly unnecessary to create a new directory for the second time--> Make this process more efficient\n",
    "splits_dir = '/Users/cagrierdem/Desktop/ongoing/POSTDOC/practice/practiceMIDI/2bar_loops_test'\n",
    "longer=[]\n",
    "normal=[]\n",
    "for i, loop in enumerate(splitted_loops):\n",
    "    for j, split in enumerate(loop):\n",
    "        save_name = f'{i}_{j}.mid'\n",
    "        if not is_shorter_or_longer_than_n_bars(split, n_bars=2, shorter=False) and not is_shorter_or_longer_than_n_bars(split, n_bars=1, shorter=True):\n",
    "            normal.append(os.path.join(splits_dir, save_name))\n",
    "            if not os.path.exists(os.path.join(splits_dir, save_name)):\n",
    "                split.save(os.path.join(splits_dir, save_name))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            longer.append(os.path.join(splits_dir, save_name))\n",
    "\n",
    "print(f'There are {len(os.listdir(splits_dir))} 2-bar (splitted) loops in the new dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 over 75 files are longer than 2 bars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inspect (once again) if there are splits longer than 2 bars or not\n",
    "#If not, you are good to proceed to the make-matrix stage\n",
    "sliced_loops = MIDIfiles(splits_dir)\n",
    "sliced_datadir = sliced_loops.get_paths()\n",
    "longs_w_issue=[]\n",
    "longs2bar = []\n",
    "for idx, file in enumerate(sliced_datadir):\n",
    "    check = MIDIgroup(file, n_bars=2)\n",
    "    if check.is_long():\n",
    "        longs_w_issue.append(file)\n",
    "    else:\n",
    "        longs2bar.append(file)\n",
    "        \n",
    "#Finally:\n",
    "print(f'{len(longs_w_issue)} over {len(sliced_datadir)} files are longer than 2 bars.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DATASET dir: /Users/cagrierdem/Desktop/ongoing/POSTDOC/practice/practiceMIDI/2bar_loops\n"
     ]
    }
   ],
   "source": [
    "DATASET = '/Users/cagrierdem/Desktop/ongoing/POSTDOC/practice/practiceMIDI/2bar_loops'\n",
    "print(f\"Processed DATASET dir: {DATASET}\")\n",
    "\n",
    "Loops = MIDIfiles(DATASET).get_paths()\n",
    "Loops.sort()\n",
    "\n",
    "# for loop in Loops:\n",
    "#     metadata = get_meta(loop)\n",
    "#     if not 'tempo' in metadata:\n",
    "#         print(f\"Tempo not found in {loop}\")\n",
    "#         break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74314d1a382f555e3e8660733563f15b7fa12644d810a3a3450ee3c4235567e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
